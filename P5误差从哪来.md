---
typora-root-url: C:\Users\Lenovo\Desktop\images
---

## Error的来源

**Error=Bias+Variance**

![img](https://github.com/YiXuanZhang1537/Notes_HungYi-Lee_ML_DL-2017/blob/main/image/v2-286539c808d9a429e69fd59fe33a16dd_720w.jpg)

![](C:\Users\Lenovo\Desktop\images\v2-286539c808d9a429e69fd59fe33a16dd_720w.jpg)

准：bias描述的是根据样本拟合出的模型输出预测结果的期望与样本真实结果的差距

确：varience描述的是样本上训练出来的模型在测试集上的表现

## 估测变量x的偏差和方差

### 评估x的偏差

$E[m] = E[1/N \sum x^n] = 1/N \sum E[x^n] =\mu $

上面这个式子是无偏估计

m分布对于$\mu$ 的离散程度（方差）：

$var[m] = \sigma^2 /N$

上式中，N越小越离散

![chapter5-5.png](https://github.com/YiXuanZhang1537/Notes_HungYi-Lee_ML_DL-2017/blob/main/image/chapter5-5.png?raw=true)

### 估算x的方差

![chapter5-6.png](https://github.com/YiXuanZhang1537/Notes_HungYi-Lee_ML_DL-2017/blob/main/image/chapter5-6.png?raw=true)

## 为什么会有很多模型

用同一个model，在不同的训练集中找到的 f^∗f∗ 就是不一样的

## 考虑不同模型之间的方差

用比较简单的模型，方差是比较小的；如果用复杂的模型，方差很大，散布比较广

这是因为简单的模型收到不同训练集的影响比较小

### 考虑不同模型之间的偏差

![chapter5-11.png](https://github.com/YiXuanZhang1537/Notes_HungYi-Lee_ML_DL-2017/blob/main/image/chapter5-11.png?raw=true)

Bias考虑的是一堆点的平均值和真实值之间的差距

直观的解释：简单的模型函数集的space比较小，所以可能space里面就没有包含靶心，肯定射不中。而复杂的模型函数集的space比较大，可能就包含的靶心，只是没有办法找到确切的靶心在哪，但足够多的，就可能得到真正的结果

![屏幕截图 2022-01-12 111016.png](https://github.com/YiXuanZhang1537/Notes_HungYi-Lee_ML_DL-2017/blob/main/image/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202022-01-12%20111016.png?raw=true)

## 偏差vs方差

![chapter5-12.png](https://github.com/YiXuanZhang1537/Notes_HungYi-Lee_ML_DL-2017/blob/main/image/chapter5-12.png?raw=true)

简单模型（左）是偏差比较大造成的误差——欠拟合

复杂模型（右）是方差过大造成的误差——过拟合

## 偏差大——欠拟合

将更多的函数加进去，或者考虑更多次幂、更复杂的模型

## 方差大——过拟合

简单粗暴的方法：更多的数据

有时不一定能够收集大量的数据，可以针对问题的理解对数据集做出调整

## 模型选择

![chapter5-15.png](https://github.com/YiXuanZhang1537/Notes_HungYi-Lee_ML_DL-2017/blob/main/image/chapter5-15.png?raw=true)

不能单纯地认为model3的误差比较小，就认为模型3好，这只是拿了一部分测试集做了测试

### 交叉验证

![chapter5-16.png](https://github.com/YiXuanZhang1537/Notes_HungYi-Lee_ML_DL-2017/blob/main/image/chapter5-16.png?raw=true)

拆分成两部分——训练集和验证集；用训练集训练模型，然后在验证集上比较，确定最好的模型之后，再用全部的训练集训练

### N-折交叉验证

![chapter5-17.png](https://github.com/YiXuanZhang1537/Notes_HungYi-Lee_ML_DL-2017/blob/main/image/chapter5-17.png?raw=true)

比如在Model1上测试效果最好，那么就用全部训练集训练1