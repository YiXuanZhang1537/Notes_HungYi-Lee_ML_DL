## 类神经网络训练不起来怎么办——（一）局部最小值和鞍点

通常我们在做优化的时候，发现**随着你的参数不断update，你的training的loss不会下降**，这个时候需要比较你的模型，如果说你发现你采用的模型没有发挥应有的效果，那么此时优化阶段显然是有问题的。

### loss搞不动

但有时你会发现，你的模型一开始就训练不起来，那么这时候不管你怎么调参，损失函数都掉不下去，这个时候可能发生的事情：

![image-20210314153200619](https://camo.githubusercontent.com/230f25bc4576853b47c1f3774549449b5fc3622143c8b188659ef9876559f3fd/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303331343135333230303631392e706e67)

这个时候你会发现，你可能是落在局部最小值处，也可能是落在鞍点处。

那么我们如何知道到底是哪种情况呢？

![image-20210314153005913](https://camo.githubusercontent.com/9411a3bd1f98936dfa9e1c0c4e629a22f149199221ce03138041d14f6b79a86f/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303331343135333030353931332e706e67)

### 相关数学求解

这里涉及微积分和线性代数的知识：

![image-20210314154450970](https://camo.githubusercontent.com/4c30d580b2a6d6202eac302e288b638ddb0217d5ac91d4e0ddc0bbff6606d212/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303331343135343435303937302e706e67)

- 第一项是$L(θ')$,就告诉我们说,当$θ$跟$θ'$很近的时候,$L(θ)$应该跟$L(θ')$还蛮靠近的
- 第二项是$(θ-θ')^Tg$

![image-20210314155508574](https://camo.githubusercontent.com/950e3130053a439dcfdedec243ddf38db056f864b9c42fc78732a203bc8e129e/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303331343135353530383537342e706e67)

​	第三项跟Hessian有关,这边有一个$H $

![image-20210314155802228](https://camo.githubusercontent.com/27e27bc5c3e0973730697c504aa0e3dc2127c55e7bb0c1ca8c6783b3b7858280/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303331343135353830323232382e706e67)

总结一下：**gradient就是一次微分,hessian就是裡面有二次微分的项目**

### Hessian对可疑点进行判断

如果我们走到一个可疑点，意味着gradient为0，绿色的一项可以直接划掉

![image-20210314160538203](https://camo.githubusercontent.com/8594c8a521f35b88f39e6e92c39b0468d90b2f8aee38c855cf6f1cdeb72ed2a1/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303331343136303533383230332e706e67)  

  **我们就可以根据红色项判断error surface的情况**

![image-20210314161411744](https://camo.githubusercontent.com/ab2823c690f6f9692930e61e55de965a3d7bb3f82ad80650b876c3a0a7c50ae0/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303331343136313431313734342e706e67)

对所有的v而言,$v^THv$都大於零,那这种矩阵叫做**positive definite 正定矩阵**,positive definite的矩阵,**它所有的eigen value特征值都是正的**

如果你今天算出一个hessian，我们就可以直接去看H矩阵的特征值eigen value

- **所有eigen value都是正的**,那就代表说这个条件成立,就$v^THv$,会大於零,也就代表说是一个local minima。所以你从hessian metric可以看出,它是不是local minima,你只要算出hessian metric算完以后,看它的eigen value发现都是正的,它就是local minima。
- 那反过来说也是一样,如果今天在这个状况,对所有的v而言,$v^THv$小於零,那H是negative definite,那就代表所有**eigen value都是负的**,就保证他是local maxima
- **那如果eigen value有正有负**,那就代表是saddle point,

### 举例说明

![image-20210314192209655](https://camo.githubusercontent.com/25590ed312c39354948fefbe2c8e9e422f4a97678e6255ad426d818b3a607d01/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303331343139323230393635352e706e67)

### 不用害怕Saddle Point

Saddle Point不但能够指出参数，还能指出更新的方向

![image-20210314200048825](https://camo.githubusercontent.com/8043617efd466010ffe09733599081df871f280c4763d7784c6032b9c184f3e0/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303331343230303034383832352e706e67)

我们$\begin{matrix}1\\1\end{matrix}$取是它对应的一个eigen vector,那我们其实只要顺著这个u的方向,顺著$\begin{matrix}1\\1\end{matrix}$

 这个vector的方向,去更新我们的参数,就可以找到一个,比saddle point的loss还要更低的点

当然，实际的作业中，几乎不会把海赛矩阵算出来。

### 鞍点vs局部最小值

**从三维空间来看，没有路可以走了；拓展到高维是否有路可走呢**

![image-20210314205016598](https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210314205016598.png)

我们就有了思路，如果我们增加参数，会不会减少local minima的个数呢？

如果你自己做实验，也支持这个假说：

![image-20210314205517453](https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210314205517453.png)

这张图的意思：越往右代表我们的critical point越像local minima，但是没有真正变成local minima，即使在最极端的情况下依然有一半的样例可以让loss下降

所以，在经验上看，local minima并没有那么常见多数时候，你发现你的梯度真的非常小，参数不再update了，往往是因为卡在了saddle point

## 类神经网络训练不起来怎么办——（二）批次与动量

### 复习：Batch的优化

![image-20210315142626597](https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210315142626597.png)

所有的Batch都看过一遍，叫做一个Epoch。今天要做的事情是Shuffle——在每次Epoch开始之前，会分一次Batch，每个Epoch的每个Batch都不一样

### 小批次vs大批次

![image-20210315143616253](https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210315143616253.png)

左边的情况是没有用Batch，Batch Size的大小和我训练集一样大（Full Batch）（一次看完所有）

右边的情况取的是极端，Batch Size等于1（干一次更新一次参数）

比较左边与右边：

![image-20210315145816823](https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210315145816823.png)

左边的方式，蓄力时间比较长，技能冷却的时间比较长，要把所有的资料看过一遍才能够update一次参数

我们看起来左边花的时间可能要长，实际上却不是。

### 大的Batch并不需要更长时间去计算梯度

**准备的是手写体的实例**

![image-20210315151645146](https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210315151645146.png)

做运算的时候，GPU可以并行运算，因此Batch Size为1000所花费的时间不等于1000个Batch花费时间的简单想加。

当然，GPU并行计算的能力是有限的，所以如果Batch Size非常大的时候，花费的时间终究还是会增加。

### Batch Size花的时间要多

在没有考虑平行运算的时候,你觉得大的 Batch 比较慢,但实际上,在有考虑平行运算的时候,一个 Epoch 大的 Batch 花的时间反而是比较少的

### Noisy（不稳定）的梯度反而有助于训练

大的 Batch Size,往往在 Training 的时候,会给你带来比较差的结果

![image-20210315155345489](https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210315155345489.png)

Full-Batch是相当于一路走下来，没有更新参数的机会；Small-Batch是曲折的，如果发现参数不太好是随时有机会调整的。

### 小的Batch对测试也有帮助

![image-20210315160405510](https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210315160405510.png)

Testing的时候小的Batch差，发生过拟合

![image-20210315161935349](https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210315161935349.png)

**大的 Batch Size,会让我们倾向於走到峡谷裡面,而小的 Batch Size,倾向於让我们走到盆地裡面**

最后比较下大的Batch Size和小的Batch Size各个方面

![image-20210315164405953](https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210315164405953.png)

![image-20210315165345030](https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210315165345030.png)

所以Batch Size的选择是鱼和熊掌不可兼得的事情

### Momentum（动量）

一般的梯度下降：

![image-20210315170131552](https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210315170131552.png)

结合梯度下降与动量

![image-20210315173052976](https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210315173052976.png)

还有一种更直白的理解方式：

![image-20210315193703079](https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210315193703079.png)

这个球，走到梯度为0的点时，因为有动量的存在，可以继续向右行走；

如果走到后面那个点发现还有动量存在，足够向右走，就可以继续寻找更低的损失点

## （三）适应性学习率

给每一个参数不同的学习率

### 当loss不再下降的时候，Gradient没有变的很小

![image-20210319093237570](https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210319093237570.png)

比如上面这种情况，error surface在两个山谷之间来回震荡

### 很少卡到鞍点或局部最小值

![image-20210319095748513](https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210319095748513.png)

这个error surface是convex的形状(可以理解为凸的或者凹的，convex optimization常翻译为“凸优化”)

要从**黑点**这个地方,这个地方当作**初始的点**,然后来做gradient descend

1，用梯度下降

![image-20210319100229839](https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210319100229839.png)

 可能会觉得学习率太大了，那么可以尝试把学习率变小一点

![image-20210319100647667](https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210319100647667.png)

但这个时候，新的问题又会出现。learning rate太小了，竖直向上那一段很斜的地方就爬不上去了

这个时候，![1639193487980](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\1639193487980.png)

这一段其实是有很多个点聚集在这里，那么我们用普通的梯度下降是不足以解决问题的 ，我们要考虑使用特制的参数

### 不同的参数需要不同的学习率

![image-20210319103709570](https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210319103709570.png)

做法：

把原来learning rate 这一项 $η$，改写成$\frac{η}{σᵢᵗ}$ $$ {θ{_i}{^{t+1}}} ← {θ{_i}{^{t}}}-{\frac{η}{σᵢᵗ}}{g{_i}{^{t}}} $$

**不同的参数我们要给它不同的σ,同时它也是iteration dependent的,不同的iteration我们也会有不同的σ**

### parameter dependent 的 learning rate有什么计算方式

#### Root Mean Square

![image-20210319150808494](https://camo.githubusercontent.com/4359b9a7e532956671f6d3753adb7d5bc951f17acd590242dffa3672d5da56d8/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303331393135303830383439342e706e67)

累加之后除以学习率，更新参数

![image-20210319160639783](https://camo.githubusercontent.com/469e3bc69b2f9f142e55c0e7581eff80d0f860608ce4922e8a9e4bf3228eb5d3/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303331393136303633393738332e706e67)

有了$\sigma $ 这一项后，就可以去调整步伐

#### RMSProp

我们希望，同一个参数、同一个方向，学习率也是可以动态调整的

![image-20210319212301760](https://camo.githubusercontent.com/e59f50c10783750f6ba07abeffb4d854a3dc64b593e6e073fa16b9b4e3053d2c/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303331393231323330313736302e706e67)

这里的$\alpha$是可以调整的，如果我们取$\alpha$ 趋近于1，就表示考虑前一项比较多，考虑后一项比较少

![image-20210319220106088](https://camo.githubusercontent.com/102ef6eed9f2339b8f0870106ba238fc00cb1b91dfd2dd155c90a89abfa94680/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303331393232303130363038382e706e67)

很平坦的地方——g算出来很小；很陡峭的地方——g算出来很大

$\alpha$ 可以调整之前各个g的影响和现在g的影响比重

通过RMS Prop就可以加快反应速度

#### Adam

Adam就是RMSProp加上Momentum

使用动态学习率的效果

![image-20210319221217246](https://camo.githubusercontent.com/5ad3e3577ac49b482ce480656f00c0308acdda66e88700d3526321926417ea94/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303331393232313231373234362e706e67)

如何解释左侧的上下痕迹？

我们在做这个σ的时候,我们是把过去所有看到的gradient,都拿来作平均

- 所以这个纵轴的方向,在这个初始的这个地方,感觉gradient很大
- 可是这边走了很长一段路以后,这个纵轴的方向,gradient算出来都很小,所以纵轴这个方向,这个y轴的方向就累积了很小的σ
- 因為我们在这个y轴的方向,看到很多很小的gradient,所以我们就累积了很小的σ,累积到一个地步以后,这个step就变很大,然后就爆走就喷出去了
- 喷出去以后没关係,有办法修正回来,因為喷出去以后,就走到了这个gradient比较大的地方,走到gradient比较大的地方以后,这个σ又慢慢的变大,σ慢慢变大以后,这个参数update的距离,Update的步伐大小就慢慢的变小

#### 解决上下波动——Learning Rate Scheduling

让学习率与时间有关 

![image-20210319222132512](https://camo.githubusercontent.com/82af1c35f678e97d4bd7399376675993f1c9ca6159534697666321c63a4e7eed/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303331393232323133323531322e706e67)

（改变$\eta$控制力度）

但是有一个与Bert有关的作业，可能需要新的算法

#### Warm Up

![image-20210319222229363](https://camo.githubusercontent.com/6b5c0e95a612266b214c2fa3d581dac366dc9a3628c6041e6d35c8ecfaf4047c/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303331393232323232393336332e706e67)

一种使用Warm Up的原因是说，一开始我们估计的$\delta$不是很准确，需要使用Warm Up进行探索

进阶的warm up ——Radam https://arxiv.org/abs/1908.03265



![1639202234731](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\1639202234731.png)

其实除了Adam，还有很多其他的模型（见补充）

接下来我们考虑怎么把这个崎岖的Error Surface挪平

![image-20210319224221772](https://camo.githubusercontent.com/9a070838983970df885d9d5acadfb2fc34f51e4481fc01336d30aa5862e6d7f0/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303331393232343232313737322e706e67)

## （四）损失函数也可能有影响

### Classification as Regression？

![image-20210320165723587](https://camo.githubusercontent.com/e122ad0a6220c23ceb918200d3c420c0e9ff5c3c3b9f0279af94179cc171e847/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303332303136353732333538372e706e67)

我们可以把Classification 当作 Regression 来看

![image-20210320170048002](https://camo.githubusercontent.com/392306accbf2b1eb905f9d836d3a67fee0d5c023dd99836eb3fdedf11180d5b2/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303332303137303034383030322e706e67)

我们的想法，让y与class的编号越接近越好

![image-20210320170353342](https://camo.githubusercontent.com/5a96971b57ce92ef7f549ccb66c6daf24bfe6404d627c774a93859d83f9fc831/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303332303137303335333334322e706e67)

但这种想法有的时候是有瑕疵的，有时候可行，有时候不可行

### Class as one-hot vector

在做分类问题时，比较常见的做法是把class用one-hot-vector表示

![image-20210320170948476](https://camo.githubusercontent.com/2371e6839b088d7084e8d511dc104dc0f5062df8c7788f0a736b16656e13197b/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303332303137303934383437362e706e67)

如果采用这样的方式，用算距离的方法算出的结果是一致的

![image-20210320185906259](https://camo.githubusercontent.com/35fb9587aa3188fc319f19aabf6b9538eb13a207be25d37ee0ad6fe77b984475/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303332303138353930363235392e706e67)

- 把a₁ a₂ a₃,乘上三个不同的Weight 加上bias,得到y₁
- 再把a₁ a₂ a₃乘上另外三个Weight,再加上另外一个bias得到y₂
- 再把a₁ a₂ a₃再乘上另外一组Weight,再加上另外一个bias得到y₃

就可以产生三组数字,所以你就可以Input一个feature的Vector,然后产生y₁ y₂ y₃,然后希望y₁ y₂ y₃,跟我们的目标越接近越好

### Classification with softmax

这是回归时候得到y的预测值的步骤：

![image-20210320190545539](https://camo.githubusercontent.com/1af46a82e9ab93563cb5fa27ef3eeec11aca53e8b96edd7e71a866e5ca07ce89/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303332303139303534353533392e706e67)

这是分类时得到y的预测值的步骤：

![image-20210320190621261](https://camo.githubusercontent.com/f14d01914b7c76d990f65153af20a254573e6e03558efd20dd521e368a0b5cdf/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303332303139303632313236312e706e67)

往往会**把y再通过一个叫做Soft-max的function得到y'**,然后我们才去计算,y'跟y hat之间的距离

加入Soft-max的原因——通俗解释是为了归一化，让大的值和小的值差距更大

### Softmax的运作机理

![image-20210320194237298](https://camo.githubusercontent.com/8c15e7ae6bd9e8fad32130cf7c8a1dfcf983492abdca781d03f30cc2f74358f2/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303332303139343233373239382e706e67)

 $$ y_i'=\frac{exp(y_i)}{\sum_j exp(y_i)} $$ 我们会先把所有的y取一个exponential,就算是负数,取exponential以后也变成正的,然后你再对它做Normalize,除掉所有y的exponential值的和,然后你就得到y'

### Lost of Classification

计算y与$\hat y$的距离不止一个做法，我们可以采用MSE Mean Square Error $$ e=\sum_i(\hat{y_i}-y_i')^2 $$ 

就是把$\hat y$ 里面每一个element拿出来计算它们的平方和，计算两个向量的距离

当然还有另外一个做法：Cross-entropy $$ e=-\sum_i\hat{y_i}\ln{y_i'} $$ （交叉熵）

交叉熵比MSE更常用，并且Software和entropy往往是绑定在一起的。

### 为什么交叉熵更常用

![image-20210320210341112](https://camo.githubusercontent.com/47b682b0c27e82ae4fc5110695942f1bb13bfb5909ced02571fe1550dcff1170/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303332303231303334313131322e706e67)

- 如果我们选择Cross-Entropy,左上角这个地方,它是有斜率的,所以你有办法透过gradient,一路往右下的地方走,
- 如果你选Mean square error的话,你就卡住了,Mean square error在这种Loss很大的地方,它是非常平坦的,它的gradient是非常小趋近於0的,如果你初始的时候在这个地方,离你的目标非常远,那它gradient又很小,你就会没有办法用gradient descent,顺利的走到右下角的地方去,

## （五）Quick Introduction of Batch Normalization

Batch Normalization “把山铲平”

批标准化（Batch Normalization,BN），又叫批量归一化，是一种用于改善人工神经网络的性能和稳定性的技术。

想法：把难做的Error Surface改掉

### $w_1$和$w_2$差很多的情况是怎么来的，举例：

![image-20210426201332297](https://camo.githubusercontent.com/fe1a78c8e55952d7e204b1aace47c0fadd157880ba98a5bfe3fd83f3fa51a7c7/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303432363230313333323239372e706e67)



这里，$x_1$ 很小，因為 $x_1$ 是直接乘上 $ w_1 $，如果 $x_1$ 的值都很小,$ w_1 $ 有一个变化的时候,它得到的,它**对 y 的影响也是小的**,对 e 的影响也是小的,它对 L 的影响就会是小的

反之，对$x_2$来说， **$x_2$ 的值都很大**,当你的 $w_2$ 有一个小小的变化的时候,虽然 $w_2$ 这个变化可能很小,但是因為它乘上了 $x_2$,$x_2$ 的值很大,那 y 的变化就很大,那 e 的变化就很大,那 L 的变化就会很大,就会导致我们在 w 这个方向上,做变化的时候,我们把 w 改变一点点,那我们的 error surface 就会有很大的变化

要解决的问题：怎么让不同维度有类似、接近的数值范围？

### Feature Normalization

标准化过程：

![image-20210426202545360](https://camo.githubusercontent.com/8d83df7a7615ab64aaa96c9ab2b513679ea08128371a17697592885009aa0a79/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303432363230323534353336302e706e67)



处理以后，会发现所有Feature Dimension的数值都在0上下，就会做出比较好的Error Surface

 	![img](https://camo.githubusercontent.com/179fac7c8c1bd8eb512b730df5d7ab61e7fb23d34a892482f6e30f0041660b64/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303432363231303632373232362e706e67)

可能a或者z没有做标准化，导致后面的结果没有标准化。所以我们的a 和 z也需要做标准化

对z做标准化的步骤

![img](https://camo.githubusercontent.com/7faf447a58037709a6b3fe4c0cb9193ddb50feb3c37d1bb6cdc612e3414c7458/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303432363231323330313933342e706e67)

接下来就把这边的每一个 z ,都去减掉 $μ$ 除以 $\sigma$,你把 $z^i$减掉 $μ$,除以 $\sigma$,就得到 $z^i$的 tilde

![img](https://camo.githubusercontent.com/9c3c761f390f4a816ec2c06ead9522bc23caa8ec97a6033ebfbd8e7882e8ca80/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303432373038343731373638372e706e67)

但是，经过这样一个步骤以后$z_1$ $z_2$  $z_3$变得彼此关联了。

怎么解决这个问题：

你现在有一个比较大的 network

- 你之前的 network,都只吃一个 input,得到一个 output
- 现在你有一个比较大的 network,这个大的 network,它是吃一堆 input,用这堆 input 在这个 network 裡面,要算出 $μ$ 跟 $\sigma$,然后接下来產生一堆 output

（比较抽象）

**那这边就会有一个问题了,因為你的训练资料裡面的 data 非常多,现在一个 data set,benchmark corpus 都上百万笔资料， GPU 的 memory,根本没有办法,把它整个 data set 的 data 都 load 进去。**

那么在实作的时候,我们只对一个 batch 裡面的 data,做 normalization,所以这招叫做 ==Batch Normalization==

但是这个Batch Normalization有一个问题，**你一定要有一个够大的 batch,你才算得出 $μ$ 跟 $\sigma$**,假设你今天,你 batch size 设 1,那你就没有什麼 $μ$ 或 $\sigma$ 可以算，因此Batch Normalization是适用于batch size比较大的时候

**Batch Normalization**里面往往会有这种设计：

![1639227445289](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\1639227445289.png)



加入$\beta$  $ \gamma$ 是为了避免出现平均值为0，调整输出的分布，这样对训练是有帮助的

### Testing部分

moving average

![image-20210427101956211](https://camo.githubusercontent.com/bc962c5a9372b929bd24a5c0163ac89bd706d50626df177f2cc0bc40196a374b/68747470733a2f2f67697465652e636f6d2f756e636c657374726f6e672f646565702d6c6561726e696e6732315f6e6f74652f7261772f6d61737465722f696d676265642f696d6167652d32303231303432373130313935363231312e706e67)

